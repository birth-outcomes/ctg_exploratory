{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction part 2\n",
    "\n",
    "This notebook contains on from `12_feature_extraction.ipynb`, looking at replicating some of the other methods in the FHRMA toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dataclasses import dataclass\n",
    "import glob\n",
    "from itertools import compress, groupby\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "@dataclass(frozen=True)\n",
    "class Paths:\n",
    "    '''Singleton object for storing paths to data and database.'''\n",
    "\n",
    "    fhrma_train_csv = './fhrma/train_test_data/traindata_csv/'\n",
    "    fhrma_test_csv = './fhrma/train_test_data/testdata_csv/'\n",
    "\n",
    "\n",
    "paths = Paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maeda et al. 2012 Baseline FHR\n",
    "\n",
    "[Maeda et al. 2012](https://benthamopen.com/contents/pdf/TOMDJ/TOMDJ-4-28.pdf) - Central Computerized Automatic Fetal Heart Rate Diagnosis with a Rapid and Direct Alarm System\n",
    "\n",
    "FHR was sampled every 250ms over a 5-minute period, and averaged every 2 seconds to determine 150 FHR (also found 150 uterine contraction data) (as there are 30 x 2 seconds in a minute, so 150 x 2 seconds in 5 minutes). FHR data were counted in intervals of 10 beats per minute (bpm) ranging from 0 to 200 bpm. The data in the interval with the most frequent FHR data was then averaged to determine the FHR baseline. \n",
    "\n",
    "So basically...\n",
    "\n",
    "1. **Find the average of every 2 seconds**\n",
    "\n",
    "2. **Look at data from a five minute period** - this will mean you are looking at a sample of 150 FHR (as each represents average of 2 seconds, and there are 150 x 2 seconds in 5 minutes)\n",
    "\n",
    "3. **Look at frequency of data in bins of 10bpm** - i.e. number of FHR that are 140-149.99, 150-150.99, and so on.\n",
    "\n",
    "4. **Find the most frequent bin** - for example, 140-150 has the most records, then just use the data from that bin\n",
    "\n",
    "5. **Find the average of the heartrates from that bin** - so might get a result like 145.5, or so on. That represents the baseline FHR for that 5 minute portion of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATLAB Implementation\n",
    "\n",
    "Boudet et al. implement this method [in the FHRMA toolbox using MATLAB](https://github.com/utsb-fmm/FHRMA/blob/master/aammaeda.m), and this is copied below:\n",
    "\n",
    "```\n",
    "sFHR=avgsubsamp(FHR,8);\n",
    "baseline=zeros(1,length(FHR));\n",
    "\n",
    "for win=[0:150:length(sFHR)-151 length(sFHR)-150]\n",
    "    \n",
    "    bins=zeros(1,25);\n",
    "\n",
    "    for i=1:150\n",
    "        bins(ceil(sFHR(win+i)/10))=bins(ceil(sFHR(win+i)/10))+1;\n",
    "    end\n",
    "    [~,bestbins]=max(bins(1:20));\n",
    "    \n",
    "    baseline(win*8+1:win*8+1200)=mean(sFHR( sFHR<=bestbins*10 & sFHR>(bestbins-1)*10 ));\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "baseline(win*8+1201:length(FHR))=baseline(win*8+1200);\n",
    "```\n",
    "\n",
    "They use a function `avgsubsamp` for subsampling by average, which is also copied below:\n",
    "\n",
    "```\n",
    "function y=avgsubsamp(x,factor)\n",
    "    y=zeros(1,floor(length(x)/factor));\n",
    "    for i=1:length(y)\n",
    "        y(i)=mean(x((i-1)*factor+1:i*factor));\n",
    "    end\n",
    "end\n",
    "```\n",
    "\n",
    "### Python Implementation\n",
    "\n",
    "#### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([168., 168., 168., 170., 170., 170., 172., 172., 172., 173.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the FHR for train01\n",
    "fhr = pd.read_csv(os.path.join(paths.fhrma_train_csv, 'train01.csv'),\n",
    "                  header=None)[0].values\n",
    "fhr[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FHRMA version of results\n",
    "md_std = io.loadmat('./fhrma/MD_std.mat')\n",
    "\n",
    "# Get array listing filenames (and hence order of the data)\n",
    "fhrma_files = np.concatenate(np.concatenate(md_std['data']['filename']))\n",
    "\n",
    "# Get array with the baseline signal as per Maeda when implemented in FHRMA\n",
    "fhrma_md = np.concatenate(md_std['data']['baseline'])\n",
    "\n",
    "# Convert array into dictionary so each record is accompanied by relevant name\n",
    "fhrma_maeda = {\n",
    "    fhrma_files[i].replace('.fhr', ''): \n",
    "    fhrma_md[i][0] for i in range(len(fhrma_files))}\n",
    "\n",
    "# Extract the same result as I am currently processing\n",
    "fhrma_result = fhrma_maeda['train01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1. Mean of FHR from every 2 seconds (i.e. 8 records)\n",
    "\n",
    "In FHRMA, they seperate the FHR into chunks of 8 (i.e. first 8 records, then next 8, then next 8, and so on). They then find the mean of each of those chunks.\n",
    "\n",
    "<mark>This doesn't clean FHR beforehand, so includes large periods of 0, and includes values outside of normal</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169.75, 172.25, 169.125, 166.75, 166.0, 166.0, 166.25, 168.5, 171.125, 172.875]\n",
      "[160.25, 161.125, 162.0, 160.375, 157.25, 154.625, 156.5, 158.375, 159.0, 159.85714285714286]\n"
     ]
    }
   ],
   "source": [
    "# Find mean of every 8 records\n",
    "sfhr = []\n",
    "start=0\n",
    "end=len(fhr)\n",
    "step=8\n",
    "for i in range(start, end, step):\n",
    "    sfhr.append(np.mean(fhr[i:i+step]))\n",
    "\n",
    "# Preview head and tail\n",
    "print(sfhr[:10])\n",
    "print(sfhr[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2. Find the most common heartrate bin in each 5 minute interval\n",
    "\n",
    "We're looking at every 5 minutes / 300 seconds (which equates to 150 of the 2 second results).\n",
    "\n",
    "We sort the heartrates into bins of 10bpm (e.g. 130-140, 140-150, 150-160), then look to see which bin is most common for that 5 minute period.\n",
    "\n",
    "FHRMA then find the mean of all heartrates from that bin across the entire recorded FHR CTG, but I am minded to suggested that this should be the mean of only the heartrates from that bin in the current five minute interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter to first five minutes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>my start points currently wrong - should find every 5 minutes, so like, 12 blocks, with last one being smaller</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169.75, 172.25, 169.125, 166.75, 166.0, 166.0, 166.25, 168.5, 171.125, 172.875, 174.0, 173.25, 170.75, 171.0, 172.0, 172.0, 173.875, 175.75, 176.0, 175.875, 174.625, 173.125, 172.0, 172.0, 173.625, 174.625, 176.0, 176.0, 176.0, 174.875, 174.0, 174.0, 175.125, 176.0, 176.0, 175.25, 173.75, 172.125, 172.0, 173.625, 174.0, 174.0, 172.75, 172.0, 172.0, 172.0, 172.125, 173.75, 174.0, 174.0, 174.0, 174.0, 173.875, 172.25, 172.0, 172.0, 172.0, 172.0, 172.0, 172.375, 173.0, 172.0, 170.25, 170.0, 170.0, 170.0, 170.0, 170.625, 172.0, 171.875, 167.25, 141.25, 131.875, 116.5, 122.875, 127.25, 128.5, 129.75, 130.5, 132.0, 123.0, 118.125, 110.5, 119.0, 126.5, 132.125, 133.25, 135.75, 142.25, 151.375, 159.0, 163.875, 166.5, 165.875, 162.125, 155.75, 150.875, 149.75, 153.125, 156.0, 154.625, 146.875, 142.125, 141.5, 140.875, 140.875, 147.625, 152.875, 156.875, 158.0, 155.75, 146.75, 139.375, 139.5, 149.5, 158.25, 161.0, 158.25, 152.125, 144.125, 134.5, 119.75, 109.5, 99.0, 79.5, 75.75, 75.25, 76.0, 74.875, 73.125, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.125, 77.5, 85.25, 94.25, 98.75, 100.875, 103.5, 116.25, 126.25, 132.625, 117.25, 108.875, 112.0, 117.75]\n"
     ]
    }
   ],
   "source": [
    "# For each of the possible start points\n",
    "# (for every possible window of 150 data points)\n",
    "start_points = len(sfhr)-149\n",
    "for i in np.arange(0, start_points):\n",
    "    # Filter to data from that 5 minute segment\n",
    "    current = sfhr[0+i:150+i]\n",
    "\n",
    "current = sfhr[0:150]\n",
    "print(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find most common bin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 18, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 18, 18, 18, 17, 15, 14, 12, 13, 13, 13, 13, 14, 14, 13, 12, 12, 12, 13, 14, 14, 14, 15, 16, 16, 17, 17, 17, 17, 16, 16, 15, 16, 16, 16, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 15, 14, 14, 15, 16, 17, 16, 16, 15, 14, 12, 11, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10, 11, 11, 12, 13, 14, 12, 11, 12, 12]\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "# Divide each value by 10 then round up to nearest integer\n",
    "bins = [math.ceil(x/10) for x in current]\n",
    "print(bins)\n",
    "\n",
    "# Find the most common bin\n",
    "mode_bin = mode(bins)*10\n",
    "print(mode_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FHRMA implementation - mean of all FHR from that bin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172.25, 171.125, 172.875, 174.0, 173.25, 170.75, 171.0, 172.0, 172.0, 173.875]\n",
      "318\n",
      "173.36320754716982\n"
     ]
    }
   ],
   "source": [
    "# Filter sFHR based on max_bin\n",
    "# If max_bin is 160, then must be less than or equal to 160\n",
    "# Must also be greater than 10 less, so 150\n",
    "mask = [(x <= mode_bin) & (x > mode_bin-10) for x in sfhr]\n",
    "filtered = list(compress(sfhr, mask))\n",
    "\n",
    "# Preview list and see its length\n",
    "print(filtered[:10])\n",
    "print(len(filtered))\n",
    "\n",
    "# Find mean of list\n",
    "mean = np.mean(filtered)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What I think this should be - mean of 5-min FHR from that bin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172.25, 171.125, 172.875, 174.0, 173.25, 170.75, 171.0, 172.0, 172.0, 173.875]\n",
      "59\n",
      "173.260593220339\n"
     ]
    }
   ],
   "source": [
    "# Filter the current five minutes to only those values that fall in the most\n",
    "# common bin\n",
    "mask = [(x <= mode_bin) & (x > mode_bin-10) for x in current]\n",
    "filtered = list(compress(current, mask))\n",
    "\n",
    "# Preview list and see its length\n",
    "print(filtered[:10])\n",
    "print(len(filtered))\n",
    "\n",
    "# Find mean of list\n",
    "mean = np.mean(filtered)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare to FHRMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([173.36320755, 173.36320755, 173.36320755, 173.36320755,\n",
       "       173.36320755, 173.36320755, 173.36320755, 173.36320755,\n",
       "       173.36320755, 173.36320755])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhrma_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Set that mean as the baseline for that 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of zeros of length of fhr\n",
    "baseline = [0] * len(fhr)\n",
    "\n",
    "# Set the record in baseline of the first 1200 records (i.e. first 5 minutes)\n",
    "# to that calculated mean\n",
    "baseline[0:1200] = [mean] * 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In FHRMA, for every recorded heartbeat in the raw FHR trace, they have set a baseline heart rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14007\n",
      "14007\n"
     ]
    }
   ],
   "source": [
    "print(len(fhrma_result))\n",
    "print(len(fhr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that they have looked at each 5 minute period, and then for the final period, just what remains (which was 807 rather than 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(173.36320754716982, 1200),\n",
       " (165.35695043103448, 3600),\n",
       " (173.36320754716982, 1200),\n",
       " (165.35695043103448, 3600),\n",
       " (155.50259067357513, 1200),\n",
       " (165.35695043103448, 1200),\n",
       " (155.50259067357513, 2007)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View counts of consecutive equal values in the results\n",
    "[(k, sum(1 for i in g)) for k,g in groupby(fhrma_result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This equates to 11 sets of 5 minutes, \n",
      "and then a final block of 3.3625 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "This equates to {len(fhr)//1200} sets of 5 minutes, \n",
    "and then a final block of {(len(fhr) % 1200)/60/4} minutes\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
