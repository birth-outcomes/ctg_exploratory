{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction part 2 - Maeda et al. 2012 baseline FHR, accelerations and decelerations\n",
    "\n",
    "This notebook contains on from `12_feature_extraction.ipynb`, looking at replicating some of the other methods in the FHRMA toolbox. As my first attempt to replicate Taylor et al. 2000 didn't match FHRMA - likely due to the differences in the Butterworth filter - I instead below tried a simpler method that just splits up the data and takes average, and compared against FHRMA results.\n",
    "\n",
    "**Some observations to be aware of:**\n",
    "* This method used modes, but that meant the baseline FHR would vary quite notably if the mode changed (as it's not uncommon for it to be a close call between modes). For example, which mode is chosen in a multi-mode situation. I have found examples where FHRMA was the min and examples where it was the max.\n",
    "* In the calculation of baseline FHR and detection of accelerations and decelerations, I have noted points where I think FHRMA's implementation differs from that described in the paper from Maeda et al. 2012. These include:\n",
    "    * Calculation of mean from all values in bin rather than 5-minute interval values in bin (as I think it makes sense it would be the interval)\n",
    "    * Calculation of fHR for last interval using points from the previous interval to pad to 150 (as I have not found mention of this in the paper - but its not implausible)\n",
    "    * Excluding reference lines in accelerations/decelerations (as these are described in the paper as being used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "import glob\n",
    "from itertools import compress, groupby\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "from statistics import multimode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "@dataclass(frozen=True)\n",
    "class Paths:\n",
    "    '''Singleton object for storing paths to data and database.'''\n",
    "\n",
    "    fhrma_train_csv = './fhrma/train_test_data/traindata_csv/'\n",
    "    fhrma_test_csv = './fhrma/train_test_data/testdata_csv/'\n",
    "    octave_maeda = './fhrma/train_test_data/maeda_octave/'\n",
    "\n",
    "\n",
    "paths = Paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for importing all csv files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv(directory, output_dict):\n",
    "    '''\n",
    "    Import csv files from provided directory and save to output_dict\n",
    "    Inputs:\n",
    "    directory - string, location of csv files\n",
    "    output_dict - dictionary, to save files to\n",
    "    '''\n",
    "    # Get list of .csv files in directory\n",
    "    files = glob.glob(os.path.join(directory, '*.csv'))\n",
    "\n",
    "    # Loop through files in the directory\n",
    "    for file in files:\n",
    "        # Get raw name of record (without path or file type)\n",
    "        name = file.replace(directory, '').replace('.csv', '')\n",
    "        # Import and save to dictionary\n",
    "        output_dict[name] = pd.read_csv(file, header=None)[0].values\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the FHR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training csv files\n",
    "raw_fhr = import_csv(\n",
    "    directory=paths.fhrma_train_csv,\n",
    "    output_dict=dict())\n",
    "\n",
    "# Import test csv files and add to same dictionary\n",
    "raw_fhr = import_csv(\n",
    "    directory=paths.fhrma_test_csv,\n",
    "    output_dict=raw_fhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Maeda baseline when implemented in Octave (so know its the same processed FHR used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octave_maeda = import_csv(\n",
    "    directory=paths.octave_maeda,\n",
    "    output_dict=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the results when processed using Maeda's methodology in FHRMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FHRMA version of results\n",
    "md_std = io.loadmat('./fhrma/MD_std.mat')\n",
    "\n",
    "# Get array listing filenames (and hence order of the data)\n",
    "fhrma_files = np.concatenate(np.concatenate(md_std['data']['filename']))\n",
    "\n",
    "# Get array with the baseline signal as per Maeda when implemented in FHRMA\n",
    "fhrma_md = np.concatenate(md_std['data']['baseline'])\n",
    "# Convert array into dictionary so each record is accompanied by relevant name\n",
    "fhrma_maeda_base = {\n",
    "    fhrma_files[i].replace('.fhr', ''): \n",
    "    fhrma_md[i][0] for i in range(len(fhrma_files))}\n",
    "\n",
    "# Same for accelerations\n",
    "fhrma_md_acc = np.concatenate(md_std['data']['accelerations'])\n",
    "fhrma_maeda_acc = {\n",
    "    fhrma_files[i].replace('.fhr', ''): \n",
    "    fhrma_md_acc[i] for i in range(len(fhrma_files))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maeda et al. 2012 Baseline FHR\n",
    "\n",
    "[Maeda et al. 2012](https://benthamopen.com/contents/pdf/TOMDJ/TOMDJ-4-28.pdf) - Central Computerized Automatic Fetal Heart Rate Diagnosis with a Rapid and Direct Alarm System\n",
    "\n",
    "FHR was sampled every 250ms over a 5-minute period, and averaged every 2 seconds to determine 150 FHR (also found 150 uterine contraction data) (as there are 30 x 2 seconds in a minute, so 150 x 2 seconds in 5 minutes). FHR data were counted in intervals of 10 beats per minute (bpm) ranging from 0 to 200 bpm. The data in the interval with the most frequent FHR data was then averaged to determine the FHR baseline. \n",
    "\n",
    "So basically...\n",
    "\n",
    "1. **Find the average of every 2 seconds**\n",
    "\n",
    "2. **Look at data from a five minute period** - this will mean you are looking at a sample of 150 FHR (as each represents average of 2 seconds, and there are 150 x 2 seconds in 5 minutes)\n",
    "\n",
    "3. **Look at frequency of data in bins of 10bpm** - i.e. number of FHR that are 140-149.99, 150-150.99, and so on.\n",
    "\n",
    "4. **Find the most frequent bin** - for example, 140-150 has the most records, then just use the data from that bin\n",
    "\n",
    "5. **Find the average of the heartrates from that bin** - so might get a result like 145.5, or so on. That represents the baseline FHR for that 5 minute portion of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATLAB Implementation\n",
    "\n",
    "Boudet et al. implement this method [in the FHRMA toolbox using MATLAB](https://github.com/utsb-fmm/FHRMA/blob/master/aammaeda.m).\n",
    "\n",
    "They used a function `aamaeda.m` with the relevant excerpt copied below:\n",
    "\n",
    "```\n",
    "sFHR=avgsubsamp(FHR,8);\n",
    "baseline=zeros(1,length(FHR));\n",
    "\n",
    "for win=[0:150:length(sFHR)-151 length(sFHR)-150]\n",
    "    \n",
    "    bins=zeros(1,25);\n",
    "\n",
    "    for i=1:150\n",
    "        bins(ceil(sFHR(win+i)/10))=bins(ceil(sFHR(win+i)/10))+1;\n",
    "    end\n",
    "    [~,bestbins]=max(bins(1:20));\n",
    "    \n",
    "    baseline(win*8+1:win*8+1200)=mean(sFHR( sFHR<=bestbins*10 & sFHR>(bestbins-1)*10 ));\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "baseline(win*8+1201:length(FHR))=baseline(win*8+1200);\n",
    "```\n",
    "\n",
    "Within that, they use a function `avgsubsamp` for subsampling by average, which is also copied below:\n",
    "\n",
    "```\n",
    "function y=avgsubsamp(x,factor)\n",
    "    y=zeros(1,floor(length(x)/factor));\n",
    "    for i=1:length(y)\n",
    "        y(i)=mean(x((i-1)*factor+1:i*factor));\n",
    "    end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function that replicates Maeda et al. 2012\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. **Convert to average of every 2 seconds** - In FHRMA, they seperate the FHR into chunks of 8 (i.e. first 8 records, then next 8, then next 8, and so on). They then find the mean of each of those chunks.\n",
    "\n",
    "2. **Find the most common heartrate bin in each 5 minute interval** - We're looking at every 5 minutes / 300 seconds (which equates to 150 of the 2 second results). We sort the heartrates into bins of 10bpm (e.g. 130-140, 140-150, 150-160), then look to see which bin is most common for that 5 minute period. FHRMA then find the mean of all heartrates from that bin across the entire recorded FHR CTG, but I am minded to suggested that this should be the mean of only the heartrates from that bin in the current five minute interval.\n",
    "\n",
    "Note: This doesn't clean FHR beforehand, so could include large periods of 0, and includes values outside of normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(fhr, match_fhrma, show_process=False):\n",
    "    '''\n",
    "    Get FHR baseline using method from Maeda et al. 2012.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fhr : array\n",
    "        Raw FHR sampled at 4Hz\n",
    "    match_fhrma : boolean\n",
    "        Whether to use a method that ensures results match FHRMA implementation\n",
    "        of Maeda's method, or whether to use the method that I currently think\n",
    "        best matches the description/intention in the original paper\n",
    "    show_process : boolean\n",
    "        Whether to print results as move through this process\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    baseline : array\n",
    "        Array where raw FHR is replaced by the baseline FHR calculated for the\n",
    "        five minute interval which it belonged to\n",
    "    '''\n",
    "    # Create array of zeros of length of fhr, which will amend to store baseline\n",
    "    baseline = [0] * len(fhr)\n",
    "\n",
    "    # Find mean of every 8 records, generating shorter version of FHR (sfhr)\n",
    "    sfhr = []\n",
    "    start=0\n",
    "    end=len(fhr)\n",
    "    step=8\n",
    "    for i in range(start, end, step):\n",
    "        sfhr.append(np.mean(fhr[i:i+step]))\n",
    "\n",
    "    # If there is a remainder when divide length by 8 (i.e. doesn't perfectly\n",
    "    # divide), then drop the final calculated FHR, as it is not from at least 8 data points\n",
    "    if len(fhr) % 8 != 0:\n",
    "        sfhr.pop()\n",
    "\n",
    "    # Print example of results\n",
    "    if show_process:\n",
    "        print(f'First 16 records in raw FHR: {fhr[:16]}')\n",
    "        print(f'First 2 records in shortened FHR (average of each 8): {sfhr[:2]}')\n",
    "\n",
    "    # Split the record into 5 minute intervals (if last less than 5 min, will be \n",
    "    # smaller). Loop through each interval\n",
    "    for i in range(0, len(sfhr), 150):\n",
    "\n",
    "        # If want to match results in FHRMA, for the final interval, filter to\n",
    "        # the last 5 minutes of the data, even if that overlaps with the\n",
    "        # previous 5 minute segment\n",
    "        if match_fhrma:\n",
    "            current = sfhr[0+i:150+i]\n",
    "            if len(current) < 150:\n",
    "                current = sfhr[-150:]\n",
    "        # Otherwise, allow the last segment to be less than 5 minutes\n",
    "        else:\n",
    "            # Filter data to that 5-minute segment\n",
    "            current = sfhr[0+i:150+i]\n",
    "\n",
    "        # Convert each record into their upper bin boundary (e.g. 149 --> 150)\n",
    "        bins = [math.ceil(x/10)*10 for x in current]\n",
    "\n",
    "        # Find the most common bin - in multi-mode situations, not yet certain\n",
    "        # on whether there is one method that would match all in FHRMA (have\n",
    "        # found some examples where they took min and some where they took max)\n",
    "        modes = multimode(bins)\n",
    "        most_common = modes[len(modes)-1]\n",
    "        if show_process:\n",
    "            print(most_common)\n",
    "\n",
    "        # If want to match results in FHRMA, filter to records from that bin\n",
    "        # from across the entire CTG\n",
    "        if match_fhrma:\n",
    "            mask = [(x <= most_common) & (x > most_common-10) for x in sfhr]\n",
    "            filtered = list(compress(sfhr, mask))\n",
    "        # Otherwise, filter to records in that bin from only that 5min interval\n",
    "        else:\n",
    "            mask = [(x <= most_common) & (x > most_common-10) for x in current]\n",
    "            filtered = list(compress(current, mask))\n",
    "\n",
    "        # Find mean of those filtered records in that bin\n",
    "        mean = np.mean(filtered)\n",
    "\n",
    "        # Set the records in baseline for that five minute interval to this mean\n",
    "        baseline[(i*8):1200+(i*8)] = [mean] * 1200\n",
    "\n",
    "    # Set any trailing 0s to the last\n",
    "    baseline[1200+(i*8):] = [baseline[1199+i*8]]*len(baseline[1200+(i*8):])\n",
    "\n",
    "    # Trim results to match original FHR length (as will overfill final small interval)\n",
    "    baseline = baseline[:len(fhr)]\n",
    "\n",
    "    # Modify final 1202 results to be the value from that final interval\n",
    "    last = copy.deepcopy(baseline[-1])\n",
    "    baseline[len(baseline)-1202:] = [last]*1202\n",
    "\n",
    "    # Print example of results from final run of that loop above\n",
    "    if show_process:\n",
    "        print(f'First 10 records of one of the intervals: {current[:10]}')\n",
    "        print(f'Conversion of those records to bins: {bins[:10]}')\n",
    "        print(f'Most common bin in the whole 5 minute interval: {most_common}')\n",
    "        print(f'Calculated baseline FHR for that interval: {mean}')\n",
    "\n",
    "    return(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare one example to FHRMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example...\n",
    "record = 'train44'\n",
    "\n",
    "# FHR signal\n",
    "fhr = pd.read_csv(os.path.join(paths.fhrma_train_csv, f'{record}.csv'),\n",
    "                  header=None)[0].values\n",
    "\n",
    "# Result from FHRMA\n",
    "fhrma_result = fhrma_maeda_base[record]\n",
    "\n",
    "# Result from Octave\n",
    "octave_result = octave_maeda[record]\n",
    "\n",
    "# Results when match_fhrma=True\n",
    "python_result = get_baseline(fhr, match_fhrma=True, show_process=False)\n",
    "\n",
    "# Show differences\n",
    "display([(k, sum(1 for i in g)) for k,g in groupby(python_result)])\n",
    "display([(k, sum(1 for i in g)) for k,g in groupby(octave_result)])\n",
    "display([(k, sum(1 for i in g)) for k,g in groupby(fhrma_result)])\n",
    "\n",
    "print(len(python_result))\n",
    "print(len(octave_result))\n",
    "print(len(fhrma_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on all available FHRMA data and compare against their results\n",
    "\n",
    "For this, I took the overall mean from the baseline record (rather than comparing each of the 5-minute means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store results\n",
    "python_maeda = dict()\n",
    "\n",
    "for key, value in raw_fhr.items():\n",
    "    python_maeda[key] = get_baseline(value, match_fhrma=True, show_process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean of each record and combine dataframes\n",
    "python_df = pd.DataFrame({\n",
    "    'record': python_maeda.keys(),\n",
    "    'python_mean': [np.mean(python_maeda[i]) for i in python_maeda.keys()]})\n",
    "octave_df = pd.DataFrame({\n",
    "    'record': octave_maeda.keys(),\n",
    "    'octave_mean': [np.mean(octave_maeda[i]) for i in octave_maeda.keys()]})\n",
    "compare_mean = pd.merge(python_df, octave_df, on='record')\n",
    "\n",
    "# Add column with difference in means\n",
    "compare_mean['diff'] = abs(compare_mean['python_mean'] - compare_mean['octave_mean'])\n",
    "\n",
    "# Preview dataframe, starting with records with the greatest difference\n",
    "display(compare_mean.sort_values(by='diff', ascending=False).head())\n",
    "\n",
    "# Record how many are exactly the same\n",
    "display((compare_mean['diff'] == 0).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhrma_df = pd.DataFrame({\n",
    "    'record': fhrma_maeda_base.keys(),\n",
    "    'fhrma_mean': [np.mean(fhrma_maeda_base[i]) for i in fhrma_maeda_base.keys()]})\n",
    "compare_mean_f = pd.merge(python_df, fhrma_df, on='record')\n",
    "\n",
    "# Add column with difference in means\n",
    "compare_mean_f['diff'] = abs(compare_mean_f['python_mean'] - compare_mean_f['fhrma_mean'])\n",
    "\n",
    "# Preview dataframe, starting with records with the greatest difference\n",
    "display(compare_mean_f.sort_values(by='diff', ascending=False).head())\n",
    "\n",
    "# Record how many are exactly the same\n",
    "display((compare_mean_f['diff'] == 0).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means(df, x, y, title):\n",
    "    '''\n",
    "    Create scatterpol comparing two columns from df.\n",
    "    Inputs:\n",
    "    df - dataframe, to plot from\n",
    "    x - string, name of column for x axis\n",
    "    y - string, name of column for y axis\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x=df[x], y=df[y])\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.title(title)\n",
    "    #plt.xlim([100, 200])\n",
    "    #plt.ylim([100, 200])\n",
    "    plt.grid()\n",
    "    ax.set_box_aspect(1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_means(compare_mean, 'python_mean', 'octave_mean',\n",
    "              'FHR baseline Maeda et al. 2012: python v.s. octave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_means(compare_mean_f, 'python_mean', 'fhrma_mean',\n",
    "              'FHR baseline Maeda et al. 2012: python v.s. FHRMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maeda et al. 2012 Accelerations and Decelerations\n",
    "\n",
    "Method description from the paper:\n",
    "* **Reference line** - \"Data-to-data difference in FHR were averaged (F bpm) and added to the baseline data to define the upper reference line (FHR baseline + F/2), and subtracted from the baseline data to define the lower reference line (FHR baseline –F/2).\"\n",
    "* **Deceleration** - \"A transient FHR decrease of more than 15 bpm below the lower reference line lasting longer than 15 seconds was defined as a deceleration. An FHR decrease appearing during transient tachycardia with a nadir of 110 bpm or more was not considered a deceleration but instead a transient recovery to the normal baseline.\"\n",
    "* **Late Deceleration** - \"The DIP SHAPE value was applied to the classification of deceleration, and was calculated by dividing the dip area ((sum of the FHR data in the deceleration) x 2) by ((deceleration amplitude x duration (seconds)) (Fig. 2). A decrease in FHR was defined as late deceleration (LD) if the following four conditions were met within 15 minutes: (1) the lag time between the contraction peak and FHR nadir was longer than 20 seconds in 60 % or more decelerations: (2) the number of deceleration was more than the contraction number – 1: (3) the DIP SHAPE value was less than 0.5: and (4) the dip variability (sum of FHR n – FHR n-1 in the deceleration) was less than 60 bpm). A decrease in FHR was defined as early deceleration (ED) if the DIP SHAPE value was less than 0.5, dip irregularity was less than 60 bpm and the lag time was almost zero.\"\n",
    "* **Variable Deceleration** - \"A decrease in FHR was defined as a variable deceleration (VD) if the DIP SHAPE was greater than 0.6 and dip variability was greater than 60 bpm\"\n",
    "* **Severe variable Deceleration** - A variable deceleration with a nadir heart rate less than 100 bpm and duration longer than 60 seconds was defined as severe variable deceleration (SVD)\n",
    "* **Prolonged Deceleration** - Deceleration lasting longer than 2 minutes\n",
    "* **Acceleration** - A transient rise in FHR of 15 bpm or more above the upper reference line lasting 15 seconds or more , after 30 weeks of pregnancy, was defined as FHR acceleration \n",
    "\n",
    "### MATLAB implementation\n",
    "\n",
    "Boudet et al. implement this method [in the FHRMA toolbox using MATLAB](https://github.com/utsb-fmm/FHRMA/blob/master/aammaeda.m), and this is copied below. First, I have described my understanding of what this function is doing.\n",
    "\n",
    "for accelerations, detect accident...\n",
    "* signal = fhr - baseline\n",
    "* threshold = 15\n",
    "* peaks are where the signal is greater than the threshold\n",
    "* find the start, end and maximum points of those accidents\n",
    "* if segment is longer than 15 seconds (15*4) then it is classed as an accident\n",
    "\n",
    "minus int...\n",
    "* a = outcome of detect accident\n",
    "* f = rerun detect accident but with threshold of 5\n",
    "* removes elements from f that are also in a\n",
    "\n",
    "it does likewise for decelerations, but instead, signal = baseline - fhr.\n",
    "\n",
    "They state that Maeda's method for acceleration and deceleration detection is the same as the standard simple method used in their toolbox.\n",
    "\n",
    "<mark>this appears to exclude the paper's concept of reference lines, which is ambiguous, but i think might be about finding the average difference between each 2second bpm HR reading and adding that to the 15bpm difference required from baseline</mark>\n",
    "\n",
    "```\n",
    "function [acc,dec,falseacc,falsedec]=simpleaddetection(fhr,baseline)\n",
    "\n",
    "acc=detectaccident(fhr-baseline,15);\n",
    "dec=detectaccident(baseline-fhr,15);\n",
    "falseacc=minusint(acc,detectaccident(fhr-baseline,5));\n",
    "falsedec=minusint(dec,detectaccident(baseline-fhr,5));\n",
    "end\n",
    "\n",
    "function accidentsample=detectaccident(sig,thre)\n",
    "\n",
    "peaks=find(sig>thre);\n",
    "accidentsample=zeros(3,0);\n",
    "while ~isempty(peaks)\n",
    "    dacc=find(sig(1:peaks)<0,1,'last');\n",
    "    if isempty(dacc)\n",
    "        dacc=1;\n",
    "    end\n",
    "    facc=find(sig(dacc+1:end)<0,1,'first')+dacc;\n",
    "    if isempty(facc)\n",
    "        facc=length(sig);\n",
    "    end\n",
    "    [~,macc]=max(sig(dacc:facc));\n",
    "    macc=macc+dacc-1;\n",
    "    if facc-dacc>15*4\n",
    "        accidentsample=[accidentsample [dacc;facc;macc]/4];\n",
    "    end   \n",
    "    peaks=peaks(peaks>facc);\n",
    "end\n",
    "end\n",
    "\n",
    "function f=minusint(a,f)\n",
    "\n",
    "for i=1:size(a,2)\n",
    "    n=find(f(1,:)>=a(1,i) &f(2,:)<=a(2,i));\n",
    "    if ~isempty(n)\n",
    "        f=f(:,[1:n-1 n+1:end]);\n",
    "    end\n",
    "end\n",
    "    \n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python implementation\n",
    "\n",
    "I have used the baseline from the FHRMA toolbox when calculating accelerations and decelerations so I can validate the method, regardless of whether my baseline methodology produced an exact match. I still use the raw FHR as I have processed it though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function for detecting accelerations or decelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_accident(sig, thre):\n",
    "    '''\n",
    "    Detect accelerations or decelerations by comparing difference betweeen FHR\n",
    "    and FHR baseline against a specified threshold.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    sig: array\n",
    "        Difference between signal and baseline - for accelerations this is\n",
    "        fhr-baseline, and for decelerations this is baseline-fhr\n",
    "    thre: int\n",
    "        Threshold for difference\n",
    "\n",
    "    Outputs:\n",
    "    --------\n",
    "    result: dataframe\n",
    "        Dataframe with the time in seconds where a peak start and began, and \n",
    "        index for the maximum of the peak (and for decelerations, this is\n",
    "        referring to a trough and the max of that trough)\n",
    "    '''\n",
    "    # Create empty list to store result\n",
    "    res = []\n",
    "\n",
    "    # Find points where value is greater than the threshold\n",
    "    peaks = np.argwhere(sig > thre).ravel()\n",
    "\n",
    "    # While we have points in peaks\n",
    "    while len(peaks) > 0:\n",
    "\n",
    "        # Extract all of sig before the first peak\n",
    "        before = sig[:peaks[0]]\n",
    "\n",
    "        # Find index of last point before peak that is < 0\n",
    "        # E.g. For accelerations, last point where FHR is not past baseline\n",
    "        dacc = np.argwhere(before < 0).ravel()\n",
    "        if len(dacc) > 0:\n",
    "            dacc = dacc[-1]\n",
    "        else:\n",
    "            dacc = 1\n",
    "\n",
    "        # Extract all of signal after that point\n",
    "        after = sig[dacc+1:]\n",
    "\n",
    "        # Find index of first point after then that is < 0\n",
    "        # Adding dacc+1 to convert it to actual location in signal (not just after peak)\n",
    "        facc = np.argwhere(after < 0).ravel()\n",
    "        if len(facc > 0):\n",
    "            facc = facc[0] + dacc + 1\n",
    "        else:\n",
    "            facc = len(sig)-1\n",
    "\n",
    "        # Filter to the values between dacc and facc (so array just has values > 0)\n",
    "        interval = sig[dacc+1:facc]\n",
    "\n",
    "        # Find the index of the maximum value in that interval\n",
    "        # Adding dacc+1 to convert it to actual location in signal\n",
    "        macc = np.argmax(interval) + dacc + 1\n",
    "\n",
    "        # Check if length of interval is more than 15 seconds - if so, save result,\n",
    "        # dividing each value by 4 so it is in seconds rather than quarter seconds -\n",
    "        # and by 60 so it is in minutes rather than seconds - and plus 1 so it\n",
    "        # matches the MATLAB results (as that is 1-indexed)\n",
    "        if len(interval) >= 15*4:\n",
    "            res.append([(x+1)/4/60 for x in [dacc, facc, macc]])\n",
    "\n",
    "        # Filter to peaks that fall after interval explored\n",
    "        peaks = peaks[peaks > facc]\n",
    "\n",
    "    # Convert result to dataframe\n",
    "    result = pd.DataFrame(res, columns=['start', 'end', 'max'])\n",
    "\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare on one example to FHRMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhr = raw_fhr['train47']\n",
    "\n",
    "# Get baseline for that record\n",
    "baseline = fhrma_maeda_base['train47']\n",
    "\n",
    "# Get acceleration result from FHRMA for that record\n",
    "fhrma_result = fhrma_maeda_acc['train47']\n",
    "\n",
    "# Use function to get my result for accelerations\n",
    "acc_df = detect_accident(fhr-baseline, 15)\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>issue: false_acc more than find in octave and causing us to lose everything</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find false accelerations\n",
    "false_acc_m = detect_accident(fhr-baseline, 5)[['start', 'end']].to_numpy()\n",
    "\n",
    "# Look for when acc falls within false_acc_m (ie. start >= false start, and \n",
    "# end <= false end) and remove those from acc\n",
    "for i in np.arange(0, len(false_acc_m)):\n",
    "    false_start = false_acc_m[i][0]\n",
    "    false_end = false_acc_m[i][1]\n",
    "    mask = ((acc_df['start'] >= false_start) & (acc_df['start'] <= false_end))\n",
    "    acc_df = acc_df[~mask]\n",
    "\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_acc_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on all results and compare against FHRMA\n",
    "\n",
    "Run on all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for record, fhr in raw_fhr.items():\n",
    "\n",
    "    # Get baseline for that record\n",
    "    baseline = fhrma_maeda_base[record]\n",
    "\n",
    "    # Get acceleration result from FHRMA for that record\n",
    "    fhrma_result = fhrma_maeda_acc[record]\n",
    "\n",
    "    # Use function to get my result for accelerations\n",
    "    python_result = detect_accident(fhr-baseline, 15)[['start', 'end']].to_numpy()\n",
    "\n",
    "    # Check if all match\n",
    "    match = np.array_equal(fhrma_result, python_result)\n",
    "\n",
    "    # Store in results\n",
    "    res.append([record, fhrma_result, python_result, match])\n",
    "\n",
    "# Convert to dataframe\n",
    "result = pd.DataFrame(res, columns=['record', 'fhrma', 'python', 'match'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview dataframe and number of differences and an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhrma = result['fhrma'][4]\n",
    "python = result['python'][4]\n",
    "\n",
    "print(len(fhrma))\n",
    "print(len(python))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring number of differences and whether its always less (as I'm suspicious that remaining discrepancies are due to not yet implementing falseacc) - but below can see that's not the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['fhrma_len'] = [len(x) for x in result['fhrma']]\n",
    "result['python_len'] = [len(x) for x in result['python']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_means(result, 'fhrma_len', 'python_len',\n",
    "              'Number of detected accelerations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
