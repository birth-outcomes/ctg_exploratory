{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction part 2\n",
    "\n",
    "This notebook contains on from `12_feature_extraction.ipynb`, looking at replicating some of the other methods in the FHRMA toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dataclasses import dataclass\n",
    "import glob\n",
    "from itertools import compress, groupby\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "@dataclass(frozen=True)\n",
    "class Paths:\n",
    "    '''Singleton object for storing paths to data and database.'''\n",
    "\n",
    "    fhrma_train_csv = './fhrma/train_test_data/traindata_csv/'\n",
    "    fhrma_test_csv = './fhrma/train_test_data/testdata_csv/'\n",
    "\n",
    "\n",
    "paths = Paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maeda et al. 2012 Baseline FHR\n",
    "\n",
    "[Maeda et al. 2012](https://benthamopen.com/contents/pdf/TOMDJ/TOMDJ-4-28.pdf) - Central Computerized Automatic Fetal Heart Rate Diagnosis with a Rapid and Direct Alarm System\n",
    "\n",
    "FHR was sampled every 250ms over a 5-minute period, and averaged every 2 seconds to determine 150 FHR (also found 150 uterine contraction data) (as there are 30 x 2 seconds in a minute, so 150 x 2 seconds in 5 minutes). FHR data were counted in intervals of 10 beats per minute (bpm) ranging from 0 to 200 bpm. The data in the interval with the most frequent FHR data was then averaged to determine the FHR baseline. \n",
    "\n",
    "So basically...\n",
    "\n",
    "1. **Find the average of every 2 seconds**\n",
    "\n",
    "2. **Look at data from a five minute period** - this will mean you are looking at a sample of 150 FHR (as each represents average of 2 seconds, and there are 150 x 2 seconds in 5 minutes)\n",
    "\n",
    "3. **Look at frequency of data in bins of 10bpm** - i.e. number of FHR that are 140-149.99, 150-150.99, and so on.\n",
    "\n",
    "4. **Find the most frequent bin** - for example, 140-150 has the most records, then just use the data from that bin\n",
    "\n",
    "5. **Find the average of the heartrates from that bin** - so might get a result like 145.5, or so on. That represents the baseline FHR for that 5 minute portion of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATLAB Implementation\n",
    "\n",
    "Boudet et al. implement this method [in the FHRMA toolbox using MATLAB](https://github.com/utsb-fmm/FHRMA/blob/master/aammaeda.m), and this is copied below:\n",
    "\n",
    "```\n",
    "sFHR=avgsubsamp(FHR,8);\n",
    "baseline=zeros(1,length(FHR));\n",
    "\n",
    "for win=[0:150:length(sFHR)-151 length(sFHR)-150]\n",
    "    \n",
    "    bins=zeros(1,25);\n",
    "\n",
    "    for i=1:150\n",
    "        bins(ceil(sFHR(win+i)/10))=bins(ceil(sFHR(win+i)/10))+1;\n",
    "    end\n",
    "    [~,bestbins]=max(bins(1:20));\n",
    "    \n",
    "    baseline(win*8+1:win*8+1200)=mean(sFHR( sFHR<=bestbins*10 & sFHR>(bestbins-1)*10 ));\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "baseline(win*8+1201:length(FHR))=baseline(win*8+1200);\n",
    "```\n",
    "\n",
    "They use a function `avgsubsamp` for subsampling by average, which is also copied below:\n",
    "\n",
    "```\n",
    "function y=avgsubsamp(x,factor)\n",
    "    y=zeros(1,floor(length(x)/factor));\n",
    "    for i=1:length(y)\n",
    "        y(i)=mean(x((i-1)*factor+1:i*factor));\n",
    "    end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation\n",
    "\n",
    "#### Set up\n",
    "\n",
    "Load the FHRMA data - the raw FHR trace, and the results from their implementation of this method on that same trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([168., 168., 168., 170., 170., 170., 172., 172., 172., 173.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the FHR for train01\n",
    "fhr = pd.read_csv(os.path.join(paths.fhrma_train_csv, 'train01.csv'),\n",
    "                  header=None)[0].values\n",
    "fhr[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FHRMA version of results\n",
    "md_std = io.loadmat('./fhrma/MD_std.mat')\n",
    "\n",
    "# Get array listing filenames (and hence order of the data)\n",
    "fhrma_files = np.concatenate(np.concatenate(md_std['data']['filename']))\n",
    "\n",
    "# Get array with the baseline signal as per Maeda when implemented in FHRMA\n",
    "fhrma_md = np.concatenate(md_std['data']['baseline'])\n",
    "\n",
    "# Convert array into dictionary so each record is accompanied by relevant name\n",
    "fhrma_maeda = {\n",
    "    fhrma_files[i].replace('.fhr', ''): \n",
    "    fhrma_md[i][0] for i in range(len(fhrma_files))}\n",
    "\n",
    "# Extract the same result as I am currently processing\n",
    "fhrma_result = fhrma_maeda['train01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function that replicates Maeda et al. 2012\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. **Convert to average of every 2 seconds** - In FHRMA, they seperate the FHR into chunks of 8 (i.e. first 8 records, then next 8, then next 8, and so on). They then find the mean of each of those chunks.\n",
    "\n",
    "2. **Find the most common heartrate bin in each 5 minute interval** - We're looking at every 5 minutes / 300 seconds (which equates to 150 of the 2 second results). We sort the heartrates into bins of 10bpm (e.g. 130-140, 140-150, 150-160), then look to see which bin is most common for that 5 minute period. FHRMA then find the mean of all heartrates from that bin across the entire recorded FHR CTG, but I am minded to suggested that this should be the mean of only the heartrates from that bin in the current five minute interval.\n",
    "\n",
    "Note: This doesn't clean FHR beforehand, so could include large periods of 0, and includes values outside of normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(fhr, match_fhrma, show_process=False):\n",
    "    '''\n",
    "    Get FHR baseline using method from Maeda et al. 2012.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fhr : array\n",
    "        Raw FHR sampled at 4Hz\n",
    "    match_fhrma : boolean\n",
    "        Whether to use a method that ensures results match FHRMA implementation\n",
    "        of Maeda's method, or whether to use the method that I currently think\n",
    "        best matches the description/intention in the original paper\n",
    "    show_process : boolean\n",
    "        Whether to print results as move through this process\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    baseline : array\n",
    "        Array where raw FHR is replaced by the baseline FHR calculated for the\n",
    "        five minute interval which it belonged to\n",
    "    '''\n",
    "    # Create array of zeros of length of fhr, which will amend to store baseline\n",
    "    baseline = [0] * len(fhr)\n",
    "\n",
    "    # Find mean of every 8 records, generating shorter version of FHR (sfhr)\n",
    "    sfhr = []\n",
    "    start=0\n",
    "    end=len(fhr)\n",
    "    step=8\n",
    "    for i in range(start, end, step):\n",
    "        sfhr.append(np.mean(fhr[i:i+step]))\n",
    "\n",
    "    # Print example of results\n",
    "    if show_process:\n",
    "        print(f'First 16 records in raw FHR: {fhr[:16]}')\n",
    "        print(f'First 2 records in shortened FHR (average of each 8): {sfhr[:2]}')\n",
    "\n",
    "    # Split the record into 5 minute intervals (if last less than 5 min, will be \n",
    "    # smaller). Loop through each interval\n",
    "    for i in range(0, len(sfhr), 150):\n",
    "        # Filter data to that 5-minute segment\n",
    "        current = sfhr[0+i:150+i]\n",
    "        # Convert each record into their upper bin boundary (e.g. 149 --> 150)\n",
    "        bins = [math.ceil(x/10)*10 for x in current]\n",
    "        # Find the most common bin\n",
    "        most_common = mode(bins)\n",
    "\n",
    "        # If want to match results in FHRMA, filter to records from that bin\n",
    "        # from across the entire CTG\n",
    "        if match_fhrma:\n",
    "            mask = [(x <= most_common) & (x > most_common-10) for x in sfhr]\n",
    "            filtered = list(compress(sfhr, mask))\n",
    "        # Otherwise, filter to records in that bin from only that 5min interval\n",
    "        else:\n",
    "            mask = [(x <= most_common) & (x > most_common-10) for x in current]\n",
    "            filtered = list(compress(current, mask))\n",
    "\n",
    "        # Find mean of those filtered records in that bin\n",
    "        mean = np.mean(filtered)\n",
    "\n",
    "        # Set the records in baseline for that five minute interval to this mean\n",
    "        baseline[0+(i*8):1200+(i*8)] = [mean] * 1200\n",
    "\n",
    "    # Trim results to match original FHR length (as will overfill final small interval)\n",
    "    baseline = baseline[:len(fhr)]\n",
    "\n",
    "    # Print example of results from final run of that loop above\n",
    "    if show_process:\n",
    "        print(f'First 10 records of one of the intervals: {current[:10]}')\n",
    "        print(f'Conversion of those records to bins: {bins[:10]}')\n",
    "        print(f'Most common bin in the whole 5 minute interval: {most_common}')\n",
    "        print(f'Calculated baseline FHR for that interval: {mean}')\n",
    "\n",
    "    return(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to FHRMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example where print results from throughout process, to help see/understand what calculations were performed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 16 records in raw FHR: [168. 168. 168. 170. 170. 170. 172. 172. 172. 173. 173. 173. 172. 172.\n",
      " 172. 171.]\n",
      "First 2 records in shortened FHR (average of each 8): [169.75, 172.25]\n",
      "First 10 records of one of the intervals: [150.25, 149.875, 146.5, 148.0, 147.75, 146.0, 149.75, 154.375, 157.875, 160.0]\n",
      "Conversion of those records to bins: [160, 150, 150, 150, 150, 150, 150, 160, 160, 160]\n",
      "Most common bin in the whole 5 minute interval: 160\n",
      "Calculated baseline FHR for that interval: 155.7343205574913\n"
     ]
    }
   ],
   "source": [
    "python_result_nomatch = get_baseline(fhr, match_fhrma=False, show_process=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of results to FHRMA. If using the method where I intend to match FHRMA, I get the same results for all expect the 150-160 bin, for which they have a different calculated mean. I have double-checked in my data below, and that is definitely the mean I get from values in that bin, so I am not certain why this difference arises.\n",
    "\n",
    "If I don't intend to match FHRMA, but instead use the method which I currently think matches the paper (mean is from 5 min interval rather than whole record), then (as expected) I don't get matching results to FHRMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(173.260593220339, 1200),\n",
       " (164.96959459459458, 1200),\n",
       " (165.3443396226415, 1200),\n",
       " (165.97619047619048, 1200),\n",
       " (175.21381578947367, 1200),\n",
       " (173.18489583333334, 1200),\n",
       " (165.03532608695653, 1200),\n",
       " (165.53605769230768, 1200),\n",
       " (155.54444444444445, 1200),\n",
       " (166.24576271186442, 1200),\n",
       " (154.58653846153845, 1200),\n",
       " (155.7343205574913, 807)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result from above where match_fhrma=False\n",
    "[(k, sum(1 for i in g)) for k,g in groupby(python_result_nomatch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(173.36320754716982, 1200),\n",
       " (165.35695043103448, 3600),\n",
       " (173.36320754716982, 2400),\n",
       " (165.35695043103448, 2400),\n",
       " (155.51384274640088, 1200),\n",
       " (165.35695043103448, 1200),\n",
       " (155.51384274640088, 2007)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results when match_fhrma=True\n",
    "python_result_match = get_baseline(fhr, match_fhrma=True, show_process=False)\n",
    "[(k, sum(1 for i in g)) for k,g in groupby(python_result_match)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(173.36320754716982, 1200),\n",
       " (165.35695043103448, 3600),\n",
       " (173.36320754716982, 1200),\n",
       " (165.35695043103448, 3600),\n",
       " (155.50259067357513, 1200),\n",
       " (165.35695043103448, 1200),\n",
       " (155.50259067357513, 2007)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View counts of consecutive equal values from FHRMA\n",
    "[(k, sum(1 for i in g)) for k,g in groupby(fhrma_result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155.51384274640088"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create shortenered FHR as in function above\n",
    "sfhr = []\n",
    "start=0\n",
    "end=len(fhr)\n",
    "step=8\n",
    "for i in range(start, end, step):\n",
    "    sfhr.append(np.mean(fhr[i:i+step]))\n",
    "\n",
    "# Convert to array\n",
    "sfhr = np.array(sfhr)\n",
    "\n",
    "# Check the mean of all values in that bin\n",
    "sfhr[(sfhr > 150) & (sfhr <= 160)].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
